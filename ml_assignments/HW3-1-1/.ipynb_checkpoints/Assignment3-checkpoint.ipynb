{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fd33643",
   "metadata": {},
   "source": [
    "### This assignment may be worked individually or in pairs. \n",
    "### Enter your name/names here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name(s) here: Ritu Gupta "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1fe226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# headers\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7c7806",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Regression and KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bccf477",
   "metadata": {},
   "source": [
    "## Part 1: Linear regression with scikit-learn\n",
    "\n",
    "In this part of the assignment, you will fit a linear regression model to an insurance dataset using the scikit-learn package. \n",
    "\n",
    "The insurance company would like to be able to estimate the annual medical expenditures they will need to pay for any customer, based on the customer's age, sex, BMI, # of children, whether they are a smoker, and their region of residence. \n",
    "\n",
    "Estimates from this model can be used to then determine how much to charge each customer for insurance (the more we think you'll cost us, the more we will charge you)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb47879",
   "metadata": {},
   "source": [
    "**Data Prep**\n",
    "\n",
    "Q1. Read the dataset from 'medical-charges.txt' into a Pandas Dataframe. Display the head of the dataset. There should be 1338 rows and 7 columns. The target column (y) is the `charges` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c05de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "df = pd.read_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3043bb91",
   "metadata": {},
   "source": [
    "Q2. Notice that there are several categorical columns. You'll need to transform these to be able to do regression. Since `sex` and `smoker` are binary in this dataset, let's do them differently than `region` which has 4 options.\n",
    "\n",
    "* Use the Pandas [get_dummies()](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) function to one-hot-encode `sex` and `smoker`. \n",
    "* Since these features are binary, we do not need to create two columns for each of them (i.e. we do not need both smoker_yes and smoker_no - just having a smoker_yes column will be sufficient), so use the `drop_first` parameter of get_dummies to create only a `smoker_yes` and a `sex_male` column. \n",
    "* Display the head of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0484464d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11737757",
   "metadata": {},
   "source": [
    "Q3. Now one-hot encode the `region` feature by again using `get_dummies()`, but this time, even though we could drop one column, let's go ahead and explicitly keep all 4 values as columns (i.e. drop_first should be set to False). Display the head of the resulting dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b43b2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a13dc1",
   "metadata": {},
   "source": [
    "Q4. An interesting thing to check with regression problems is whether any of the individual features correlate very strongly with the label. Use the `corr()` method on the dataframe to take a look at this.\n",
    "\n",
    "Answer as a comment: Do you see any features with a strong correlation to the label?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad660fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b86aa6a",
   "metadata": {},
   "source": [
    "Q5. Create a plot to show the difference in charges between the smokers and the non-smokers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3a1ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ece359c",
   "metadata": {},
   "source": [
    "Q6. Let's explore the relationship between `age` and `charges`. Create a scatter plot of all data points to show age vs charges. \n",
    "\n",
    "Answer as a comment: What do you notice about the nature of this relationship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a4ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9b1624",
   "metadata": {},
   "source": [
    "#### Simple Linear Regression\n",
    "**Fit a simple linear regression model to predict `charges` from `age`.**\n",
    "\n",
    "Q7. \n",
    "* Grab the `age` column from the dataframe and call it something like `x`.\n",
    "* Grab the `charges` column from the dataframe and call it something like `y`.\n",
    "* When doing simple linear regression (one feature), you need to convert the features from a Series to a list of lists. You can do this by doing `x = x.values.reshape(-1,1)`, where the (-1,1) means (all rows, one column). \n",
    "* Do the same to the labels (`y = y.values.reshape(-1,1)`). \n",
    "* Verify that you have a list of lists for both x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012a960",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08424490",
   "metadata": {},
   "source": [
    "**Using the holdout method**\n",
    "\n",
    "Q8. Use [sklearn.model_selection.train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split your dataset into training and test sets. Do an 80%-20% split. Display how many records are in the training set and how many are in the test set. Set the random_state argument to your favorite number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c24d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffda89c",
   "metadata": {},
   "source": [
    "Q9. Fit a simple linear regression model to the x and y data. This computes the B0 and B1 coefficients.\n",
    "* Create a [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) object. \n",
    "* Call `fit` on it and pass in the training set.\n",
    "* Print the slope and the intercept of the equation with the `.coef_` and `.intercept_` attributes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa8b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0695225",
   "metadata": {},
   "source": [
    "Q10. Now that you've fit the model on the training set, you can evaluate it on the test set. Call `predict` on the linear regression object and pass in the test set. Save the return value - these are all of the predicted values under the model for the test set. \n",
    "\n",
    "Compute some metrics to see how well this model fits the test data. Use `sklearn.metrics` to print out the MAE, MSE, RMSE, and R2 for the test set under this model. Remember that you have the actual y values for your test set, up in Q8.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b56fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "\n",
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8c799f",
   "metadata": {},
   "source": [
    "Q11. Let's see what the best fit line looks like with the test data. Scatter-plot the test data (x_test, y_test). Then line-plot the model predictions for the test data (x_test, y_test_preds). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b64976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308eb6bf",
   "metadata": {},
   "source": [
    "Q12. Now, go back up to your Q8, change the random_state to a different number, and re-run Q9, Q10, Q11. \n",
    "\n",
    "Answer as a comment: What happened and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a24492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer as a comment here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d04b36",
   "metadata": {},
   "source": [
    "**Using cross-validation**\n",
    "\n",
    "Q13. We've discussed and seen the issues that can happen when we do a single hold-out test set. Cross validation is a better, more robust way to evaluate our models. Use `sklearn.model_selection.cross_val_score` to perform 5-fold cross validation on a simple linear regression model. \n",
    "\n",
    "You will pass the FULL dataset (x and y from before the train/test split in Q8) into `cross_val_score` which will automatically divide it into the number of folds you tell it to, fit a linear regression model to the training set for each fold, and test it on the test set for each fold. It will return a numpy array with the R2 on the test set for each fold. Average these R2 scores to print out the generalization estimate of the model.\n",
    "\n",
    "On average, after 5 trials with 5 different test sets, this is how well we think a linear regression of using `age` to predict `charges` will work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b417e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed2a22c",
   "metadata": {},
   "source": [
    "#### Multiple Linear Regression\n",
    "**Fit a multiple linear regression model to predict `charges` from `age` and `smoker`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3b2aa1",
   "metadata": {},
   "source": [
    "Q14. Now let's see if we can get a better model by including another feature.\n",
    "* From the one-hot-encoded dataframe (the result of Q3), grab both the `age` and `smoker_yes` columns. Call it something like x. \n",
    "* (No need to call a reshape this time, since it is multi-dimensional data now.)\n",
    "* You already have the y's.\n",
    "* Create a new `sklearn.linear_model.LinearRegression` object. (Or you can re-use the one you already have.)\n",
    "* Pass it all into a `sklearn.model_selection.cross_val_score` with a 5-fold CV.\n",
    "* Print out the average R2.\n",
    "\n",
    "Answer as a comment: What happens when you include `smoker_yes`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1db535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bdb411",
   "metadata": {},
   "source": [
    "Q15. Let's go one more step and see if including ALL of our features is even better at predicting the `charges` than using just `age` and `smoker`.\n",
    "\n",
    "* From the one-hot-encoded dataframe (the result of Q3), grab all the features, but NOT the target. Call it something like x.\n",
    "* (No need to call a reshape this time, since it is multi-dimensional data now.)\n",
    "* You already have the y's.\n",
    "* Create a new sklearn.linear_model.LinearRegression object. (Or you can re-use the one you already have.)\n",
    "* Pass it all into a sklearn.model_selection.cross_val_score with a 5-fold CV.\n",
    "* Print out the average R2 and the adjusted R2.\n",
    "\n",
    "Answer as a comment: What happens when you use ALL of the features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbef0e5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c60daf",
   "metadata": {},
   "source": [
    "Q16. Build the final model on the entire dataset. \n",
    "* You should already have your x from the previous question (Q15).\n",
    "* You already have the y's.\n",
    "* Create a new `sklearn.linear_model.LinearRegression` object, or you can re-use the one you already have.\n",
    "* Call `fit` and pass in all the data (x, y).\n",
    "* Print out the coefficients and the intercept of the fitted model. The coefficients correspond to the the order in which the features are in the dataframe (x).\n",
    "\n",
    "This defines your multiple linear regression equation! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cfb422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08d42fc",
   "metadata": {},
   "source": [
    "## Part 2: K-Nearest Neighbors from scratch\n",
    "\n",
    "In this part of the assignment you'll implement the K-Nearest Neighbors (KNN) classification algorithm to classify patients as either having or not having diabetic retinopathy. For this task we'll be using the same Diabetic Retinopathy data set which was used in the previous assignment on decision trees. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04ffa20",
   "metadata": {},
   "source": [
    "You may use the following function to print a confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc4cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(TP, FN, FP, TN):\n",
    "    \n",
    "    table_data = [[TP,FN],[FP,TN]]\n",
    "    df = pd.DataFrame(table_data, columns =['Predicted 1','Predicted 0'])\n",
    "    df = df.rename(index={0: 'Actual 1', 1: 'Actual 0'})\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb2b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you may use these constants if you want\n",
    "LABEL_COLUMN = 19\n",
    "BINARY_COLUMNS = {0,1,18}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edf52cf",
   "metadata": {},
   "source": [
    "Q1. Normalize the data so that each feature value lies between `[0-1]`.\n",
    "\n",
    "In class, we talked about why scaling the data is critical to KNN. We also talked about how data scaling should be done *inside the cross validataion loop*. This means that the scaling parameters should be based on the **training set only**, in order to prevent data leakage. Then the test data will need to be scaled, using the parameters found on the **training** data.\n",
    "\n",
    "Fill in the function to take in a training dataset and a test dataset and normalize them correctly. Return the normalized datasets.\n",
    "\n",
    "Caution: Return NEW datasets that have been normalized - do not normalize the datasets in-place, so that this can be run numerous times without altering the original data or normalizing already normalized data.\n",
    "\n",
    "Hint: When using dataframes, you can do this without a loop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2521ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(train, test):\n",
    "    # your code goes here\n",
    "    return train_norm, test_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbcfd93",
   "metadata": {},
   "source": [
    "Q2. The distance calculation method is central to the KNN algorithm. In this assignment you'll be using the Euclidean distance. \n",
    "\n",
    "Implement a function that takes in one data point (as a list or a series), and the training data (as a dataframe), and calculates the Euclidian distance from the single data point to each of the data points in the training data.\n",
    "\n",
    "Add a column to the dataframe called `distance` that contains the Euclidian distance value from each row to the single data point, and return the dataframe with this new column filled in. \n",
    "\n",
    "\n",
    "Hint: For KNN, the distance calculations are the most time-consuming part of the algorithm. Even though computing Euclidian distance seems like a simple, and therefore quick, calculation, running it thousands of times, inside of a nested 5-fold cross-validation for example, can cause this algorithm to take a very long time to run, depending on your implementation. So you want to do this efficiently.\n",
    "\n",
    "Remember, you almost never need to loop a Dataframe! Pandas DataFrames have been specifically optimized for fast operations on large datasets, by [vectorizing](https://www.quantifisolutions.com/vectorization-part-2-why-and-what) calculations across all rows at once.\n",
    "\n",
    "If you use a DataFrame, you should not write a loop to calculate each of the Euclidian distances one at a time. Look at [this post](https://stackoverflow.com/questions/46908388/find-euclidean-distance-from-a-point-to-rows-in-pandas-dataframe?rq=1) for more info.\n",
    "\n",
    "Caution: Be careful not to use the label in your distance calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8568727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distances(point, df):\n",
    "    # your code goes here\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e91c9c3",
   "metadata": {},
   "source": [
    "Q3. Build your KNN classifier.\n",
    "\n",
    "This function takes in a training set (as a dataframe), a test set (as a dataframe), and a k to use, and classifies all data points in the test set, using the data in the training set and the given k.\n",
    "\n",
    "It should return the predicted labels for the test set as a list.\n",
    "\n",
    "Caution: Remember to normalize your data before doing distance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knn(train_set, test_set, k):\n",
    "    # your code goes here\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80cc7f6",
   "metadata": {},
   "source": [
    "Q4. Find the best value of k for this data. \n",
    "\n",
    "Try k ranging from 1 to 10 (odds only). For each k value, use a 5-fold cross validation to evaluate the accuracy with that k. In each fold of CV, divide your data into a training set and a validation set. Print out the best value of k and the accuracy achieved with that value. Return the best value of k. If there is a tie for best k, use the lowest of the k values.\n",
    "\n",
    "Hint: This is the *inner* loop of a nested cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70de520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_k(data):\n",
    "    # your code goes here    \n",
    "    return best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da24b15",
   "metadata": {},
   "source": [
    "Q5. Now measure the accuracy of your classifier using 5-fold cross validation. \n",
    "\n",
    "In each fold of this CV, divide your data into a training set and a test set. The training set should get sent through your code for Q4, resulting in a value of k to use. Using that k, calculate an accuracy on the test set. You will average the accuracy over all 5 folds to obtain the final accuracy measurement. \n",
    "\n",
    "Print the accuracy, the confusion matrix, and the precision and recall for class label 1 (patients that have been diagnosed with the disease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a77f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def run_CV(filename):\n",
    "    # read in data\n",
    "    data = pd.read_csv(filename, header = None)\n",
    "    print(\"dataset size:\", data.shape)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # your code goes here\n",
    "\n",
    "    end_time = time.time()\n",
    "    print('\\nTotal time (seconds):', end_time - start_time)\n",
    "\n",
    "run_CV('messidor_features.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4367164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
